{
  "cells": [
    {
      "cell_type": "code",
      "id": "pBxX3I1kYwojaamntSxiNZTK",
      "metadata": {
        "tags": [],
        "id": "pBxX3I1kYwojaamntSxiNZTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd72b94-38cb-4ba0-948b-22f4bb9d6e1d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "REG_MODE = 'baseline'\n",
        "SIGR_ALPHA = 0.1   # Strength of the physics constraint\n",
        "SKETCH_DIM = 64    # Dimension of the random observer\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.1\n",
        "EPOCHS = 400\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if torch.backends.mps.is_available(): DEVICE = 'mps'\n",
        "\n",
        "print(f\"Training on device: {DEVICE}\")\n",
        "\n",
        "def get_data_loaders():\n",
        "    print('==> Preparing data with Strong Augmentation...')\n",
        "\n",
        "    mean = (0.5071, 0.4867, 0.4408)\n",
        "    std = (0.2675, 0.2565, 0.2761)\n",
        "\n",
        "    # FIX 1: Add RandAugment\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "    # Increase workers to handle augmentation load\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "# ------------------------------------------\n",
        "# Physics Engine: The Regularizers\n",
        "# ------------------------------------------\n",
        "\n",
        "def sigreg_weak_loss(x, sketch_dim=64):\n",
        "    \"\"\"\n",
        "    Forces Covariance(x) ~ Identity.\n",
        "    Matches the 2nd Moment (Spherical Cloud).\n",
        "    \"\"\"\n",
        "    N, C = x.size()\n",
        "    # 1. Sketching (Optional for C=512, but good for consistency)\n",
        "    if C > sketch_dim:\n",
        "        S = torch.randn(sketch_dim, C, device=x.device) / (C ** 0.5)\n",
        "        x = x @ S.T  # [N, sketch_dim]\n",
        "    else:\n",
        "        sketch_dim = C\n",
        "\n",
        "    # 2. Centering & Covariance\n",
        "    x = x - x.mean(dim=0, keepdim=True)\n",
        "    cov = (x.T @ x) / (N - 1 + 1e-6)\n",
        "\n",
        "    # 3. Target Identity\n",
        "    target = torch.eye(sketch_dim, device=x.device)\n",
        "\n",
        "    # 4. Off-diagonal suppression + Diagonal maintenance\n",
        "    return torch.norm(cov - target, p='fro')\n",
        "\n",
        "def sigreg_strong_loss(x, sketch_dim=64):\n",
        "    \"\"\"\n",
        "    Forces ECF(x) ~ ECF(Gaussian).\n",
        "    Matches ALL Moments (Maximum Entropy Cloud).\n",
        "    Exact implementation of LeJEPA Algorithm 1.\n",
        "    \"\"\"\n",
        "    N, C = x.size()\n",
        "\n",
        "    # 1. Projection (The Observer)\n",
        "    # Project channels down to sketch_dim\n",
        "    A = torch.randn(C, sketch_dim, device=x.device)\n",
        "    A = A / (A.norm(p=2, dim=0, keepdim=True) + 1e-6)\n",
        "\n",
        "    # 2. Integration Points\n",
        "    t = torch.linspace(-5, 5, 17, device=x.device)\n",
        "\n",
        "    # 3. Theoretical Gaussian CF\n",
        "    exp_f = torch.exp(-0.5 * t**2)\n",
        "\n",
        "    # 4. Empirical CF\n",
        "    # proj: [N, sketch_dim]\n",
        "    proj = x @ A\n",
        "\n",
        "    # args: [N, sketch_dim, T]\n",
        "    args = proj.unsqueeze(2) * t.view(1, 1, -1)\n",
        "\n",
        "    # ecf: [sketch_dim, T] (Mean over batch)\n",
        "    ecf = torch.exp(1j * args).mean(dim=0)\n",
        "\n",
        "    # 5. Weighted L2 Distance\n",
        "    # |ecf - gauss|^2 * gauss_weight\n",
        "    diff_sq = (ecf - exp_f.unsqueeze(0)).abs().square()\n",
        "    err = diff_sq * exp_f.unsqueeze(0)\n",
        "\n",
        "    # 6. Integrate\n",
        "    loss = torch.trapz(err, t, dim=1) * N\n",
        "\n",
        "    return loss.mean()\n",
        "\n",
        "class LinearBlock(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, reg_mode='baseline', sketch_dim=64):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(dim, hidden_dim)\n",
        "        # Note: NO BATCH NORM. We rely purely on SIGReg.\n",
        "        self.reg_mode = reg_mode\n",
        "        self.sketch_dim = sketch_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        pre_act = self.fc(x)\n",
        "\n",
        "        reg_loss = torch.tensor(0.0, device=x.device)\n",
        "        if self.reg_mode != 'baseline':\n",
        "            if self.reg_mode == 'weak':\n",
        "                reg_loss = sigreg_weak_loss(pre_act, self.sketch_dim)\n",
        "            elif self.reg_mode == 'strong':\n",
        "                reg_loss = sigreg_strong_loss(pre_act, self.sketch_dim)\n",
        "\n",
        "        out = F.relu(pre_act)\n",
        "\n",
        "        return out, reg_loss\n",
        "\n",
        "class ThermoMLP(nn.Module):\n",
        "    def __init__(self, input_dim=3072, hidden_dim=1024, num_classes=100, depth=6, reg_mode='weak', sketch_dim=64):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        # Input Layer\n",
        "        layers.append(LinearBlock(input_dim, hidden_dim, reg_mode))\n",
        "\n",
        "        # Deep Layers (No Residuals!)\n",
        "        for _ in range(depth - 2):\n",
        "            layers.append(LinearBlock(hidden_dim, hidden_dim, reg_mode, sketch_dim))\n",
        "\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten: [B, C, H, W] -> [B, 3072]\n",
        "        x = x.flatten(1)\n",
        "\n",
        "        total_phys_loss = 0.0\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x, l_loss = layer(x)\n",
        "            total_phys_loss += l_loss\n",
        "\n",
        "        out = self.classifier(x)\n",
        "\n",
        "        # Normalize loss scale\n",
        "        return out, (total_phys_loss / len(self.layers))\n",
        "\n",
        "# ==========================================\n",
        "# 5. Training Engine (Updated for Mixup/CutMix)\n",
        "# ==========================================\n",
        "def train(epoch, net, trainloader, optimizer, criterion):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    phys_loss_meter = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward\n",
        "        outputs, p_loss = net(inputs)\n",
        "\n",
        "        # Task Loss\n",
        "        c_loss = criterion(outputs, targets)\n",
        "\n",
        "        # Total Loss\n",
        "        loss = (1 - SIGR_ALPHA) * c_loss + (SIGR_ALPHA * p_loss)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += ((1 - SIGR_ALPHA) * c_loss).item()\n",
        "        phys_loss_meter += (SIGR_ALPHA * p_loss).item()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100. * correct / total\n",
        "    return train_loss / (batch_idx + 1), acc, phys_loss_meter / (batch_idx + 1)\n",
        "\n",
        "def test(epoch, net, testloader, criterion):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "            outputs, _ = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    acc = 100. * correct / total\n",
        "    return test_loss / (batch_idx + 1), acc\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    trainloader, testloader = get_data_loaders()\n",
        "\n",
        "    net = ThermoMLP(reg_mode=REG_MODE, sketch_dim=SKETCH_DIM).to(DEVICE)\n",
        "    net = net.to(DEVICE)\n",
        "\n",
        "    # Standard CrossEntropy for final eval, SoftLabel for training is handled by Mixup logic\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=0.0, weight_decay=0.0)\n",
        "\n",
        "    print(f\"Starting training for {EPOCHS} epochs with RandAugment + Mixup/CutMix...\")\n",
        "\n",
        "    best_acc = 0\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss, train_acc, physics_loss = train(epoch, net, trainloader, optimizer, criterion)\n",
        "        test_loss, test_acc = test(epoch, net, testloader, criterion)\n",
        "\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            # torch.save(net.state_dict(), f'thermo_resnet_{REG_MODE}.pth')\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        print(f\"Epoch {epoch+1} | T: {epoch_time:.0f}s | \"\n",
        "              f\"Train: {train_loss:.4f} ({train_acc:.1f}%) | \"\n",
        "              f\"Phys: {physics_loss:.2f} | \"\n",
        "              f\"Val: {test_loss:.4f} ({test_acc:.2f}%) | \"\n",
        "              f\"Best: {best_acc:.2f}%\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on device: cuda\n",
            "==> Preparing data with Strong Augmentation...\n",
            "Starting training for 400 epochs with RandAugment + Mixup/CutMix...\n",
            "Epoch 1 | T: 10s | Train: 4.1038 (2.4%) | Phys: 0.00 | Val: 4.3251 (3.59%) | Best: 3.59%\n",
            "Epoch 2 | T: 10s | Train: 3.7169 (6.2%) | Phys: 0.00 | Val: 4.0630 (5.83%) | Best: 5.83%\n",
            "Epoch 3 | T: 10s | Train: 3.5495 (8.5%) | Phys: 0.00 | Val: 3.9161 (8.83%) | Best: 8.83%\n",
            "Epoch 4 | T: 10s | Train: 3.4411 (10.7%) | Phys: 0.00 | Val: 3.8087 (10.81%) | Best: 10.81%\n",
            "Epoch 5 | T: 10s | Train: 3.3573 (12.3%) | Phys: 0.00 | Val: 3.7454 (12.26%) | Best: 12.26%\n",
            "Epoch 6 | T: 9s | Train: 3.2945 (13.4%) | Phys: 0.00 | Val: 3.7299 (12.18%) | Best: 12.26%\n",
            "Epoch 7 | T: 9s | Train: 3.2449 (14.3%) | Phys: 0.00 | Val: 3.6849 (13.83%) | Best: 13.83%\n",
            "Epoch 8 | T: 9s | Train: 3.2033 (15.2%) | Phys: 0.00 | Val: 3.6110 (14.62%) | Best: 14.62%\n",
            "Epoch 9 | T: 10s | Train: 3.1591 (16.0%) | Phys: 0.00 | Val: 3.5787 (15.28%) | Best: 15.28%\n",
            "Epoch 10 | T: 9s | Train: 3.1201 (16.7%) | Phys: 0.00 | Val: 3.5512 (15.48%) | Best: 15.48%\n",
            "Epoch 11 | T: 9s | Train: 3.0840 (17.4%) | Phys: 0.00 | Val: 3.5412 (15.89%) | Best: 15.89%\n",
            "Epoch 12 | T: 9s | Train: 3.0531 (18.1%) | Phys: 0.00 | Val: 3.5075 (16.67%) | Best: 16.67%\n",
            "Epoch 13 | T: 10s | Train: 3.0254 (18.7%) | Phys: 0.00 | Val: 3.4481 (17.31%) | Best: 17.31%\n",
            "Epoch 14 | T: 9s | Train: 2.9919 (19.3%) | Phys: 0.00 | Val: 3.4622 (17.39%) | Best: 17.39%\n",
            "Epoch 15 | T: 9s | Train: 2.9694 (19.8%) | Phys: 0.00 | Val: 3.4497 (17.77%) | Best: 17.77%\n",
            "Epoch 16 | T: 10s | Train: 2.9415 (20.4%) | Phys: 0.00 | Val: 3.4148 (17.87%) | Best: 17.87%\n",
            "Epoch 17 | T: 10s | Train: 2.9203 (21.0%) | Phys: 0.00 | Val: 3.4401 (18.19%) | Best: 18.19%\n",
            "Epoch 18 | T: 10s | Train: 2.8976 (21.4%) | Phys: 0.00 | Val: 3.4074 (18.48%) | Best: 18.48%\n",
            "Epoch 19 | T: 10s | Train: 2.8797 (21.6%) | Phys: 0.00 | Val: 3.3838 (19.00%) | Best: 19.00%\n",
            "Epoch 20 | T: 10s | Train: 2.8531 (22.2%) | Phys: 0.00 | Val: 3.3584 (19.77%) | Best: 19.77%\n",
            "Epoch 21 | T: 9s | Train: 2.8339 (22.5%) | Phys: 0.00 | Val: 3.3406 (19.68%) | Best: 19.77%\n",
            "Epoch 22 | T: 10s | Train: 2.8130 (23.1%) | Phys: 0.00 | Val: 3.3454 (19.51%) | Best: 19.77%\n",
            "Epoch 23 | T: 10s | Train: 2.7957 (23.4%) | Phys: 0.00 | Val: 3.3447 (20.02%) | Best: 20.02%\n",
            "Epoch 24 | T: 9s | Train: 2.7768 (23.8%) | Phys: 0.00 | Val: 3.3586 (19.83%) | Best: 20.02%\n",
            "Epoch 25 | T: 9s | Train: 2.7605 (24.2%) | Phys: 0.00 | Val: 3.3687 (19.73%) | Best: 20.02%\n",
            "Epoch 26 | T: 10s | Train: 2.7379 (24.5%) | Phys: 0.00 | Val: 3.2961 (20.46%) | Best: 20.46%\n",
            "Epoch 27 | T: 10s | Train: 2.7229 (24.9%) | Phys: 0.00 | Val: 3.2727 (21.09%) | Best: 21.09%\n",
            "Epoch 28 | T: 9s | Train: 2.7039 (25.0%) | Phys: 0.00 | Val: 3.2872 (20.72%) | Best: 21.09%\n",
            "Epoch 29 | T: 10s | Train: 2.6887 (25.6%) | Phys: 0.00 | Val: 3.2593 (21.64%) | Best: 21.64%\n",
            "Epoch 30 | T: 10s | Train: 2.6696 (25.7%) | Phys: 0.00 | Val: 3.2569 (21.54%) | Best: 21.64%\n",
            "Epoch 31 | T: 10s | Train: 2.6532 (26.1%) | Phys: 0.00 | Val: 3.2831 (21.25%) | Best: 21.64%\n",
            "Epoch 32 | T: 10s | Train: 2.6376 (26.6%) | Phys: 0.00 | Val: 3.2541 (21.83%) | Best: 21.83%\n",
            "Epoch 33 | T: 10s | Train: 2.6249 (26.9%) | Phys: 0.00 | Val: 3.2355 (21.64%) | Best: 21.83%\n",
            "Epoch 34 | T: 9s | Train: 2.6084 (27.4%) | Phys: 0.00 | Val: 3.2720 (21.40%) | Best: 21.83%\n",
            "Epoch 35 | T: 10s | Train: 2.5928 (27.7%) | Phys: 0.00 | Val: 3.2372 (22.05%) | Best: 22.05%\n",
            "Epoch 36 | T: 10s | Train: 2.5795 (27.9%) | Phys: 0.00 | Val: 3.2216 (22.47%) | Best: 22.47%\n",
            "Epoch 37 | T: 10s | Train: 2.5643 (28.3%) | Phys: 0.00 | Val: 3.1934 (22.61%) | Best: 22.61%\n",
            "Epoch 38 | T: 9s | Train: 2.5459 (28.4%) | Phys: 0.00 | Val: 3.2084 (22.68%) | Best: 22.68%\n",
            "Epoch 39 | T: 10s | Train: 2.5277 (28.8%) | Phys: 0.00 | Val: 3.1782 (23.84%) | Best: 23.84%\n",
            "Epoch 40 | T: 9s | Train: 2.5178 (29.2%) | Phys: 0.00 | Val: 3.1852 (23.07%) | Best: 23.84%\n",
            "Epoch 41 | T: 9s | Train: 2.5038 (29.5%) | Phys: 0.00 | Val: 3.2037 (23.38%) | Best: 23.84%\n",
            "Epoch 42 | T: 10s | Train: 2.4879 (29.6%) | Phys: 0.00 | Val: 3.1800 (23.85%) | Best: 23.85%\n",
            "Epoch 43 | T: 10s | Train: 2.4752 (29.9%) | Phys: 0.00 | Val: 3.1688 (23.55%) | Best: 23.85%\n",
            "Epoch 44 | T: 9s | Train: 2.4610 (30.3%) | Phys: 0.00 | Val: 3.1482 (23.99%) | Best: 23.99%\n",
            "Epoch 45 | T: 10s | Train: 2.4401 (30.8%) | Phys: 0.00 | Val: 3.1667 (23.91%) | Best: 23.99%\n",
            "Epoch 46 | T: 9s | Train: 2.4321 (30.9%) | Phys: 0.00 | Val: 3.1897 (23.76%) | Best: 23.99%\n",
            "Epoch 47 | T: 9s | Train: 2.4147 (31.4%) | Phys: 0.00 | Val: 3.1505 (24.43%) | Best: 24.43%\n",
            "Epoch 48 | T: 9s | Train: 2.4034 (31.5%) | Phys: 0.00 | Val: 3.1691 (23.61%) | Best: 24.43%\n",
            "Epoch 49 | T: 10s | Train: 2.3886 (31.9%) | Phys: 0.00 | Val: 3.1339 (24.07%) | Best: 24.43%\n",
            "Epoch 50 | T: 9s | Train: 2.3709 (32.4%) | Phys: 0.00 | Val: 3.1173 (24.67%) | Best: 24.67%\n",
            "Epoch 51 | T: 9s | Train: 2.3576 (32.6%) | Phys: 0.00 | Val: 3.1524 (24.37%) | Best: 24.67%\n",
            "Epoch 52 | T: 10s | Train: 2.3429 (32.9%) | Phys: 0.00 | Val: 3.0992 (25.86%) | Best: 25.86%\n",
            "Epoch 53 | T: 9s | Train: 2.3269 (33.3%) | Phys: 0.00 | Val: 3.1690 (24.32%) | Best: 25.86%\n",
            "Epoch 54 | T: 9s | Train: 2.3169 (33.6%) | Phys: 0.00 | Val: 3.1430 (24.80%) | Best: 25.86%\n",
            "Epoch 55 | T: 10s | Train: 2.2968 (33.8%) | Phys: 0.00 | Val: 3.1457 (24.81%) | Best: 25.86%\n",
            "Epoch 56 | T: 9s | Train: 2.2881 (34.1%) | Phys: 0.00 | Val: 3.1820 (24.19%) | Best: 25.86%\n",
            "Epoch 57 | T: 9s | Train: 2.2693 (34.4%) | Phys: 0.00 | Val: 3.1604 (24.25%) | Best: 25.86%\n",
            "Epoch 58 | T: 10s | Train: 2.2568 (34.8%) | Phys: 0.00 | Val: 3.1129 (25.43%) | Best: 25.86%\n",
            "Epoch 59 | T: 9s | Train: 2.2398 (35.0%) | Phys: 0.00 | Val: 3.1112 (25.03%) | Best: 25.86%\n",
            "Epoch 60 | T: 10s | Train: 2.2278 (35.4%) | Phys: 0.00 | Val: 3.1330 (25.02%) | Best: 25.86%\n",
            "Epoch 61 | T: 10s | Train: 2.2126 (35.7%) | Phys: 0.00 | Val: 3.1915 (24.13%) | Best: 25.86%\n",
            "Epoch 62 | T: 10s | Train: 2.1982 (36.0%) | Phys: 0.00 | Val: 3.1851 (24.83%) | Best: 25.86%\n",
            "Epoch 63 | T: 10s | Train: 2.1803 (36.5%) | Phys: 0.00 | Val: 3.1423 (24.95%) | Best: 25.86%\n",
            "Epoch 64 | T: 9s | Train: 2.1721 (36.8%) | Phys: 0.00 | Val: 3.0907 (25.22%) | Best: 25.86%\n",
            "Epoch 65 | T: 10s | Train: 2.1513 (37.0%) | Phys: 0.00 | Val: 3.1328 (24.85%) | Best: 25.86%\n",
            "Epoch 66 | T: 10s | Train: 2.1431 (37.4%) | Phys: 0.00 | Val: 3.1493 (25.30%) | Best: 25.86%\n",
            "Epoch 67 | T: 10s | Train: 2.1189 (38.0%) | Phys: 0.00 | Val: 3.0999 (25.81%) | Best: 25.86%\n",
            "Epoch 68 | T: 10s | Train: 2.1083 (38.1%) | Phys: 0.00 | Val: 3.1467 (25.29%) | Best: 25.86%\n",
            "Epoch 69 | T: 9s | Train: 2.0911 (38.6%) | Phys: 0.00 | Val: 3.1488 (25.41%) | Best: 25.86%\n",
            "Epoch 70 | T: 9s | Train: 2.0758 (38.8%) | Phys: 0.00 | Val: 3.1169 (26.03%) | Best: 26.03%\n",
            "Epoch 71 | T: 10s | Train: 2.0634 (39.2%) | Phys: 0.00 | Val: 3.2232 (24.27%) | Best: 26.03%\n",
            "Epoch 72 | T: 9s | Train: 2.0472 (39.3%) | Phys: 0.00 | Val: 3.1204 (26.14%) | Best: 26.14%\n",
            "Epoch 73 | T: 9s | Train: 2.0311 (39.8%) | Phys: 0.00 | Val: 3.1068 (26.77%) | Best: 26.77%\n",
            "Epoch 74 | T: 10s | Train: 2.0220 (40.1%) | Phys: 0.00 | Val: 3.1335 (25.66%) | Best: 26.77%\n",
            "Epoch 75 | T: 10s | Train: 2.0007 (40.5%) | Phys: 0.00 | Val: 3.1719 (25.99%) | Best: 26.77%\n",
            "Epoch 76 | T: 9s | Train: 1.9853 (40.9%) | Phys: 0.00 | Val: 3.1656 (25.60%) | Best: 26.77%\n",
            "Epoch 77 | T: 9s | Train: 1.9683 (41.2%) | Phys: 0.00 | Val: 3.1952 (25.55%) | Best: 26.77%\n",
            "Epoch 78 | T: 10s | Train: 1.9524 (42.1%) | Phys: 0.00 | Val: 3.1439 (25.80%) | Best: 26.77%\n",
            "Epoch 79 | T: 9s | Train: 1.9398 (42.3%) | Phys: 0.00 | Val: 3.1543 (25.89%) | Best: 26.77%\n",
            "Epoch 80 | T: 10s | Train: 1.9267 (42.4%) | Phys: 0.00 | Val: 3.1422 (26.46%) | Best: 26.77%\n",
            "Epoch 81 | T: 10s | Train: 1.9075 (43.0%) | Phys: 0.00 | Val: 3.1568 (26.44%) | Best: 26.77%\n",
            "Epoch 82 | T: 9s | Train: 1.8932 (43.2%) | Phys: 0.00 | Val: 3.1929 (25.83%) | Best: 26.77%\n",
            "Epoch 83 | T: 9s | Train: 1.8769 (43.5%) | Phys: 0.00 | Val: 3.1795 (25.84%) | Best: 26.77%\n",
            "Epoch 84 | T: 10s | Train: 1.8594 (43.9%) | Phys: 0.00 | Val: 3.2042 (26.08%) | Best: 26.77%\n",
            "Epoch 85 | T: 10s | Train: 1.8478 (44.4%) | Phys: 0.00 | Val: 3.2183 (25.17%) | Best: 26.77%\n",
            "Epoch 86 | T: 10s | Train: 1.8310 (44.6%) | Phys: 0.00 | Val: 3.2387 (25.63%) | Best: 26.77%\n",
            "Epoch 87 | T: 10s | Train: 1.8118 (45.0%) | Phys: 0.00 | Val: 3.2246 (26.04%) | Best: 26.77%\n",
            "Epoch 88 | T: 10s | Train: 1.7956 (45.6%) | Phys: 0.00 | Val: 3.2097 (26.01%) | Best: 26.77%\n",
            "Epoch 89 | T: 10s | Train: 1.7788 (46.0%) | Phys: 0.00 | Val: 3.2459 (25.44%) | Best: 26.77%\n",
            "Epoch 90 | T: 9s | Train: 1.7648 (46.3%) | Phys: 0.00 | Val: 3.2660 (25.99%) | Best: 26.77%\n",
            "Epoch 91 | T: 10s | Train: 1.7466 (46.7%) | Phys: 0.00 | Val: 3.2903 (24.89%) | Best: 26.77%\n",
            "Epoch 92 | T: 10s | Train: 1.7326 (47.1%) | Phys: 0.00 | Val: 3.2420 (25.74%) | Best: 26.77%\n",
            "Epoch 93 | T: 10s | Train: 1.7136 (47.4%) | Phys: 0.00 | Val: 3.2975 (25.12%) | Best: 26.77%\n",
            "Epoch 94 | T: 10s | Train: 1.7029 (47.8%) | Phys: 0.00 | Val: 3.2627 (25.79%) | Best: 26.77%\n",
            "Epoch 95 | T: 10s | Train: 1.6822 (48.6%) | Phys: 0.00 | Val: 3.3379 (25.26%) | Best: 26.77%\n",
            "Epoch 96 | T: 9s | Train: 1.6700 (48.6%) | Phys: 0.00 | Val: 3.3292 (25.52%) | Best: 26.77%\n",
            "Epoch 97 | T: 10s | Train: 1.6507 (49.0%) | Phys: 0.00 | Val: 3.3219 (25.85%) | Best: 26.77%\n",
            "Epoch 98 | T: 10s | Train: 1.6346 (49.4%) | Phys: 0.00 | Val: 3.3837 (25.37%) | Best: 26.77%\n",
            "Epoch 99 | T: 10s | Train: 1.6200 (49.7%) | Phys: 0.00 | Val: 3.3299 (25.95%) | Best: 26.77%\n",
            "Epoch 100 | T: 10s | Train: 1.6044 (50.5%) | Phys: 0.00 | Val: 3.3601 (26.07%) | Best: 26.77%\n",
            "Epoch 101 | T: 10s | Train: 1.5895 (50.9%) | Phys: 0.00 | Val: 3.3527 (25.45%) | Best: 26.77%\n",
            "Epoch 102 | T: 10s | Train: 1.5685 (51.4%) | Phys: 0.00 | Val: 3.3764 (25.37%) | Best: 26.77%\n",
            "Epoch 103 | T: 9s | Train: 1.5559 (51.7%) | Phys: 0.00 | Val: 3.4040 (25.37%) | Best: 26.77%\n",
            "Epoch 104 | T: 10s | Train: 1.5364 (52.3%) | Phys: 0.00 | Val: 3.3793 (25.56%) | Best: 26.77%\n",
            "Epoch 105 | T: 10s | Train: 1.5165 (52.9%) | Phys: 0.00 | Val: 3.4079 (25.61%) | Best: 26.77%\n",
            "Epoch 106 | T: 10s | Train: 1.5010 (52.7%) | Phys: 0.00 | Val: 3.4339 (25.18%) | Best: 26.77%\n",
            "Epoch 107 | T: 10s | Train: 1.4874 (53.4%) | Phys: 0.00 | Val: 3.4311 (25.54%) | Best: 26.77%\n",
            "Epoch 108 | T: 10s | Train: 1.4728 (53.6%) | Phys: 0.00 | Val: 3.4470 (26.51%) | Best: 26.77%\n",
            "Epoch 109 | T: 9s | Train: 1.4622 (54.1%) | Phys: 0.00 | Val: 3.4625 (25.55%) | Best: 26.77%\n",
            "Epoch 110 | T: 10s | Train: 1.4389 (54.6%) | Phys: 0.00 | Val: 3.4944 (25.51%) | Best: 26.77%\n",
            "Epoch 111 | T: 9s | Train: 1.4239 (55.1%) | Phys: 0.00 | Val: 3.5018 (25.56%) | Best: 26.77%\n",
            "Epoch 112 | T: 10s | Train: 1.4077 (55.4%) | Phys: 0.00 | Val: 3.5049 (25.50%) | Best: 26.77%\n",
            "Epoch 113 | T: 10s | Train: 1.3929 (55.7%) | Phys: 0.00 | Val: 3.5457 (25.31%) | Best: 26.77%\n",
            "Epoch 114 | T: 10s | Train: 1.3701 (56.6%) | Phys: 0.00 | Val: 3.5920 (25.01%) | Best: 26.77%\n",
            "Epoch 115 | T: 10s | Train: 1.3552 (57.2%) | Phys: 0.00 | Val: 3.5773 (24.93%) | Best: 26.77%\n",
            "Epoch 116 | T: 9s | Train: 1.3471 (57.2%) | Phys: 0.00 | Val: 3.6059 (24.62%) | Best: 26.77%\n",
            "Epoch 117 | T: 10s | Train: 1.3233 (57.9%) | Phys: 0.00 | Val: 3.6149 (24.84%) | Best: 26.77%\n",
            "Epoch 118 | T: 10s | Train: 1.3150 (58.1%) | Phys: 0.00 | Val: 3.6061 (25.46%) | Best: 26.77%\n",
            "Epoch 119 | T: 10s | Train: 1.2957 (58.4%) | Phys: 0.00 | Val: 3.6366 (25.21%) | Best: 26.77%\n",
            "Epoch 120 | T: 10s | Train: 1.2816 (59.0%) | Phys: 0.00 | Val: 3.6600 (24.96%) | Best: 26.77%\n",
            "Epoch 121 | T: 9s | Train: 1.2712 (59.3%) | Phys: 0.00 | Val: 3.6373 (25.48%) | Best: 26.77%\n",
            "Epoch 122 | T: 9s | Train: 1.2507 (59.9%) | Phys: 0.00 | Val: 3.6598 (25.06%) | Best: 26.77%\n",
            "Epoch 123 | T: 10s | Train: 1.2300 (60.4%) | Phys: 0.00 | Val: 3.6789 (25.54%) | Best: 26.77%\n",
            "Epoch 124 | T: 10s | Train: 1.2138 (60.8%) | Phys: 0.00 | Val: 3.7098 (25.17%) | Best: 26.77%\n",
            "Epoch 125 | T: 10s | Train: 1.2071 (61.2%) | Phys: 0.00 | Val: 3.7284 (25.05%) | Best: 26.77%\n",
            "Epoch 126 | T: 10s | Train: 1.1866 (61.7%) | Phys: 0.00 | Val: 3.7436 (24.87%) | Best: 26.77%\n",
            "Epoch 127 | T: 10s | Train: 1.1724 (62.1%) | Phys: 0.00 | Val: 3.7596 (25.65%) | Best: 26.77%\n",
            "Epoch 128 | T: 9s | Train: 1.1584 (62.5%) | Phys: 0.00 | Val: 3.8088 (24.65%) | Best: 26.77%\n",
            "Epoch 129 | T: 9s | Train: 1.1465 (62.7%) | Phys: 0.00 | Val: 3.7945 (25.23%) | Best: 26.77%\n",
            "Epoch 130 | T: 10s | Train: 1.1213 (63.2%) | Phys: 0.00 | Val: 3.8101 (25.19%) | Best: 26.77%\n",
            "Epoch 131 | T: 10s | Train: 1.1143 (63.4%) | Phys: 0.00 | Val: 3.8864 (24.93%) | Best: 26.77%\n",
            "Epoch 132 | T: 10s | Train: 1.1005 (64.3%) | Phys: 0.00 | Val: 3.8223 (25.40%) | Best: 26.77%\n",
            "Epoch 133 | T: 10s | Train: 1.0866 (64.3%) | Phys: 0.00 | Val: 3.8542 (25.03%) | Best: 26.77%\n",
            "Epoch 134 | T: 10s | Train: 1.0689 (65.1%) | Phys: 0.00 | Val: 3.8832 (25.11%) | Best: 26.77%\n",
            "Epoch 135 | T: 9s | Train: 1.0524 (65.6%) | Phys: 0.00 | Val: 3.9267 (24.91%) | Best: 26.77%\n",
            "Epoch 136 | T: 10s | Train: 1.0476 (65.7%) | Phys: 0.00 | Val: 3.9330 (24.64%) | Best: 26.77%\n",
            "Epoch 137 | T: 10s | Train: 1.0260 (66.3%) | Phys: 0.00 | Val: 3.8967 (25.18%) | Best: 26.77%\n",
            "Epoch 138 | T: 9s | Train: 1.0140 (66.3%) | Phys: 0.00 | Val: 3.9880 (24.42%) | Best: 26.77%\n",
            "Epoch 139 | T: 10s | Train: 1.0039 (67.1%) | Phys: 0.00 | Val: 3.9781 (24.61%) | Best: 26.77%\n",
            "Epoch 140 | T: 10s | Train: 0.9903 (67.4%) | Phys: 0.00 | Val: 4.0296 (24.36%) | Best: 26.77%\n",
            "Epoch 141 | T: 9s | Train: 0.9668 (68.0%) | Phys: 0.00 | Val: 4.0331 (25.16%) | Best: 26.77%\n",
            "Epoch 142 | T: 10s | Train: 0.9617 (68.2%) | Phys: 0.00 | Val: 4.0416 (24.41%) | Best: 26.77%\n",
            "Epoch 143 | T: 10s | Train: 0.9514 (68.4%) | Phys: 0.00 | Val: 4.0635 (24.82%) | Best: 26.77%\n",
            "Epoch 144 | T: 9s | Train: 0.9339 (69.0%) | Phys: 0.00 | Val: 4.0567 (24.32%) | Best: 26.77%\n",
            "Epoch 145 | T: 10s | Train: 0.9203 (69.7%) | Phys: 0.00 | Val: 4.0884 (24.89%) | Best: 26.77%\n",
            "Epoch 146 | T: 10s | Train: 0.9039 (70.0%) | Phys: 0.00 | Val: 4.1161 (24.34%) | Best: 26.77%\n",
            "Epoch 147 | T: 9s | Train: 0.8947 (70.3%) | Phys: 0.00 | Val: 4.1685 (24.13%) | Best: 26.77%\n",
            "Epoch 148 | T: 9s | Train: 0.8867 (70.4%) | Phys: 0.00 | Val: 4.1213 (24.91%) | Best: 26.77%\n",
            "Epoch 149 | T: 10s | Train: 0.8707 (71.0%) | Phys: 0.00 | Val: 4.1950 (24.17%) | Best: 26.77%\n",
            "Epoch 150 | T: 10s | Train: 0.8551 (71.5%) | Phys: 0.00 | Val: 4.1716 (24.68%) | Best: 26.77%\n",
            "Epoch 151 | T: 9s | Train: 0.8385 (72.0%) | Phys: 0.00 | Val: 4.2056 (24.56%) | Best: 26.77%\n",
            "Epoch 152 | T: 10s | Train: 0.8346 (72.0%) | Phys: 0.00 | Val: 4.2428 (25.06%) | Best: 26.77%\n",
            "Epoch 153 | T: 10s | Train: 0.8156 (72.5%) | Phys: 0.00 | Val: 4.2865 (24.91%) | Best: 26.77%\n",
            "Epoch 154 | T: 9s | Train: 0.8097 (73.0%) | Phys: 0.00 | Val: 4.3016 (24.75%) | Best: 26.77%\n",
            "Epoch 155 | T: 9s | Train: 0.7969 (73.1%) | Phys: 0.00 | Val: 4.3606 (24.08%) | Best: 26.77%\n",
            "Epoch 156 | T: 10s | Train: 0.7848 (73.4%) | Phys: 0.00 | Val: 4.3911 (24.07%) | Best: 26.77%\n",
            "Epoch 157 | T: 9s | Train: 0.7700 (74.0%) | Phys: 0.00 | Val: 4.4405 (24.32%) | Best: 26.77%\n",
            "Epoch 158 | T: 10s | Train: 0.7619 (74.2%) | Phys: 0.00 | Val: 4.4041 (24.67%) | Best: 26.77%\n",
            "Epoch 159 | T: 10s | Train: 0.7506 (74.6%) | Phys: 0.00 | Val: 4.4326 (24.60%) | Best: 26.77%\n",
            "Epoch 160 | T: 9s | Train: 0.7423 (74.9%) | Phys: 0.00 | Val: 4.4657 (24.72%) | Best: 26.77%\n",
            "Epoch 161 | T: 9s | Train: 0.7263 (75.2%) | Phys: 0.00 | Val: 4.4937 (24.29%) | Best: 26.77%\n",
            "Epoch 162 | T: 10s | Train: 0.7170 (75.7%) | Phys: 0.00 | Val: 4.4558 (24.39%) | Best: 26.77%\n",
            "Epoch 163 | T: 9s | Train: 0.7121 (75.9%) | Phys: 0.00 | Val: 4.4694 (24.72%) | Best: 26.77%\n",
            "Epoch 164 | T: 9s | Train: 0.6959 (76.4%) | Phys: 0.00 | Val: 4.5846 (24.45%) | Best: 26.77%\n",
            "Epoch 165 | T: 10s | Train: 0.6882 (76.5%) | Phys: 0.00 | Val: 4.5374 (24.58%) | Best: 26.77%\n",
            "Epoch 166 | T: 10s | Train: 0.6758 (77.0%) | Phys: 0.00 | Val: 4.5951 (24.77%) | Best: 26.77%\n",
            "Epoch 167 | T: 9s | Train: 0.6753 (77.2%) | Phys: 0.00 | Val: 4.6361 (23.64%) | Best: 26.77%\n",
            "Epoch 168 | T: 9s | Train: 0.6589 (77.6%) | Phys: 0.00 | Val: 4.6493 (24.56%) | Best: 26.77%\n",
            "Epoch 169 | T: 10s | Train: 0.6492 (77.7%) | Phys: 0.00 | Val: 4.5654 (25.19%) | Best: 26.77%\n",
            "Epoch 170 | T: 10s | Train: 0.6394 (78.1%) | Phys: 0.00 | Val: 4.6117 (25.03%) | Best: 26.77%\n",
            "Epoch 171 | T: 9s | Train: 0.6329 (78.4%) | Phys: 0.00 | Val: 4.6046 (24.87%) | Best: 26.77%\n",
            "Epoch 172 | T: 10s | Train: 0.6250 (78.6%) | Phys: 0.00 | Val: 4.6347 (24.57%) | Best: 26.77%\n",
            "Epoch 173 | T: 9s | Train: 0.6082 (79.1%) | Phys: 0.00 | Val: 4.6716 (24.32%) | Best: 26.77%\n",
            "Epoch 174 | T: 9s | Train: 0.6011 (79.3%) | Phys: 0.00 | Val: 4.7000 (24.52%) | Best: 26.77%\n",
            "Epoch 175 | T: 10s | Train: 0.5936 (79.7%) | Phys: 0.00 | Val: 4.7119 (24.46%) | Best: 26.77%\n",
            "Epoch 176 | T: 10s | Train: 0.5808 (80.1%) | Phys: 0.00 | Val: 4.7536 (24.75%) | Best: 26.77%\n",
            "Epoch 177 | T: 10s | Train: 0.5741 (80.4%) | Phys: 0.00 | Val: 4.8028 (24.57%) | Best: 26.77%\n",
            "Epoch 178 | T: 10s | Train: 0.5656 (80.5%) | Phys: 0.00 | Val: 4.7946 (24.39%) | Best: 26.77%\n",
            "Epoch 179 | T: 9s | Train: 0.5583 (80.7%) | Phys: 0.00 | Val: 4.7782 (24.67%) | Best: 26.77%\n",
            "Epoch 180 | T: 9s | Train: 0.5507 (81.0%) | Phys: 0.00 | Val: 4.8673 (24.17%) | Best: 26.77%\n",
            "Epoch 181 | T: 9s | Train: 0.5458 (81.1%) | Phys: 0.00 | Val: 4.8376 (24.11%) | Best: 26.77%\n",
            "Epoch 182 | T: 10s | Train: 0.5330 (81.7%) | Phys: 0.00 | Val: 4.8485 (24.36%) | Best: 26.77%\n",
            "Epoch 183 | T: 9s | Train: 0.5306 (81.6%) | Phys: 0.00 | Val: 4.8609 (24.64%) | Best: 26.77%\n",
            "Epoch 184 | T: 10s | Train: 0.5237 (82.0%) | Phys: 0.00 | Val: 4.9174 (24.32%) | Best: 26.77%\n",
            "Epoch 185 | T: 10s | Train: 0.5182 (82.2%) | Phys: 0.00 | Val: 4.9311 (24.59%) | Best: 26.77%\n",
            "Epoch 186 | T: 9s | Train: 0.5054 (82.5%) | Phys: 0.00 | Val: 4.9526 (24.49%) | Best: 26.77%\n",
            "Epoch 187 | T: 9s | Train: 0.4983 (82.9%) | Phys: 0.00 | Val: 5.0363 (24.41%) | Best: 26.77%\n",
            "Epoch 188 | T: 10s | Train: 0.4929 (82.9%) | Phys: 0.00 | Val: 5.0096 (24.27%) | Best: 26.77%\n",
            "Epoch 189 | T: 9s | Train: 0.4831 (83.2%) | Phys: 0.00 | Val: 5.0382 (23.94%) | Best: 26.77%\n",
            "Epoch 190 | T: 9s | Train: 0.4777 (83.6%) | Phys: 0.00 | Val: 4.9936 (25.30%) | Best: 26.77%\n",
            "Epoch 191 | T: 10s | Train: 0.4694 (83.5%) | Phys: 0.00 | Val: 5.1049 (23.83%) | Best: 26.77%\n",
            "Epoch 192 | T: 9s | Train: 0.4706 (83.7%) | Phys: 0.00 | Val: 5.1115 (24.27%) | Best: 26.77%\n",
            "Epoch 193 | T: 9s | Train: 0.4606 (84.0%) | Phys: 0.00 | Val: 5.1527 (24.27%) | Best: 26.77%\n",
            "Epoch 194 | T: 9s | Train: 0.4561 (84.1%) | Phys: 0.00 | Val: 5.1168 (24.67%) | Best: 26.77%\n",
            "Epoch 195 | T: 10s | Train: 0.4488 (84.3%) | Phys: 0.00 | Val: 5.1108 (24.73%) | Best: 26.77%\n",
            "Epoch 196 | T: 9s | Train: 0.4445 (84.8%) | Phys: 0.00 | Val: 5.1438 (24.63%) | Best: 26.77%\n",
            "Epoch 197 | T: 10s | Train: 0.4381 (84.7%) | Phys: 0.00 | Val: 5.1667 (24.06%) | Best: 26.77%\n",
            "Epoch 198 | T: 10s | Train: 0.4321 (85.0%) | Phys: 0.00 | Val: 5.2108 (24.20%) | Best: 26.77%\n",
            "Epoch 199 | T: 9s | Train: 0.4244 (85.3%) | Phys: 0.00 | Val: 5.2285 (24.25%) | Best: 26.77%\n",
            "Epoch 200 | T: 10s | Train: 0.4234 (85.3%) | Phys: 0.00 | Val: 5.1668 (25.35%) | Best: 26.77%\n",
            "Epoch 201 | T: 10s | Train: 0.4094 (85.8%) | Phys: 0.00 | Val: 5.2470 (24.61%) | Best: 26.77%\n",
            "Epoch 202 | T: 10s | Train: 0.4086 (85.8%) | Phys: 0.00 | Val: 5.3092 (24.54%) | Best: 26.77%\n",
            "Epoch 203 | T: 10s | Train: 0.4009 (85.8%) | Phys: 0.00 | Val: 5.2577 (24.30%) | Best: 26.77%\n",
            "Epoch 204 | T: 10s | Train: 0.3992 (86.1%) | Phys: 0.00 | Val: 5.2353 (24.57%) | Best: 26.77%\n",
            "Epoch 205 | T: 10s | Train: 0.3938 (86.3%) | Phys: 0.00 | Val: 5.3219 (25.05%) | Best: 26.77%\n",
            "Epoch 206 | T: 9s | Train: 0.3907 (86.6%) | Phys: 0.00 | Val: 5.2793 (25.56%) | Best: 26.77%\n",
            "Epoch 207 | T: 10s | Train: 0.3854 (86.7%) | Phys: 0.00 | Val: 5.2748 (25.14%) | Best: 26.77%\n",
            "Epoch 208 | T: 10s | Train: 0.3803 (86.7%) | Phys: 0.00 | Val: 5.3407 (24.84%) | Best: 26.77%\n",
            "Epoch 209 | T: 10s | Train: 0.3765 (86.8%) | Phys: 0.00 | Val: 5.3386 (24.66%) | Best: 26.77%\n",
            "Epoch 210 | T: 9s | Train: 0.3693 (87.1%) | Phys: 0.00 | Val: 5.4176 (24.65%) | Best: 26.77%\n",
            "Epoch 211 | T: 10s | Train: 0.3592 (87.5%) | Phys: 0.00 | Val: 5.4089 (24.33%) | Best: 26.77%\n",
            "Epoch 212 | T: 9s | Train: 0.3678 (87.3%) | Phys: 0.00 | Val: 5.3375 (24.90%) | Best: 26.77%\n",
            "Epoch 213 | T: 10s | Train: 0.3538 (87.7%) | Phys: 0.00 | Val: 5.4781 (24.25%) | Best: 26.77%\n",
            "Epoch 214 | T: 10s | Train: 0.3547 (87.7%) | Phys: 0.00 | Val: 5.4449 (24.49%) | Best: 26.77%\n",
            "Epoch 215 | T: 9s | Train: 0.3468 (88.0%) | Phys: 0.00 | Val: 5.4379 (24.88%) | Best: 26.77%\n",
            "Epoch 216 | T: 9s | Train: 0.3437 (87.9%) | Phys: 0.00 | Val: 5.4535 (24.81%) | Best: 26.77%\n",
            "Epoch 217 | T: 10s | Train: 0.3418 (88.2%) | Phys: 0.00 | Val: 5.4931 (24.79%) | Best: 26.77%\n",
            "Epoch 218 | T: 10s | Train: 0.3359 (88.3%) | Phys: 0.00 | Val: 5.5478 (24.31%) | Best: 26.77%\n",
            "Epoch 219 | T: 10s | Train: 0.3316 (88.5%) | Phys: 0.00 | Val: 5.5899 (24.55%) | Best: 26.77%\n",
            "Epoch 220 | T: 10s | Train: 0.3305 (88.7%) | Phys: 0.00 | Val: 5.5486 (25.04%) | Best: 26.77%\n",
            "Epoch 221 | T: 10s | Train: 0.3279 (88.6%) | Phys: 0.00 | Val: 5.5054 (24.84%) | Best: 26.77%\n",
            "Epoch 222 | T: 10s | Train: 0.3219 (88.9%) | Phys: 0.00 | Val: 5.5369 (24.91%) | Best: 26.77%\n",
            "Epoch 223 | T: 9s | Train: 0.3134 (89.1%) | Phys: 0.00 | Val: 5.5265 (25.17%) | Best: 26.77%\n",
            "Epoch 224 | T: 10s | Train: 0.3088 (89.2%) | Phys: 0.00 | Val: 5.6511 (24.17%) | Best: 26.77%\n",
            "Epoch 225 | T: 10s | Train: 0.3114 (89.2%) | Phys: 0.00 | Val: 5.6753 (23.88%) | Best: 26.77%\n",
            "Epoch 226 | T: 9s | Train: 0.3094 (89.1%) | Phys: 0.00 | Val: 5.5969 (24.77%) | Best: 26.77%\n",
            "Epoch 227 | T: 10s | Train: 0.3075 (89.3%) | Phys: 0.00 | Val: 5.6046 (24.52%) | Best: 26.77%\n",
            "Epoch 228 | T: 9s | Train: 0.3022 (89.3%) | Phys: 0.00 | Val: 5.6271 (24.46%) | Best: 26.77%\n",
            "Epoch 229 | T: 10s | Train: 0.2965 (89.8%) | Phys: 0.00 | Val: 5.6121 (25.07%) | Best: 26.77%\n",
            "Epoch 230 | T: 10s | Train: 0.2981 (89.7%) | Phys: 0.00 | Val: 5.7046 (24.47%) | Best: 26.77%\n",
            "Epoch 231 | T: 10s | Train: 0.2928 (89.8%) | Phys: 0.00 | Val: 5.6536 (25.04%) | Best: 26.77%\n",
            "Epoch 232 | T: 9s | Train: 0.2846 (89.9%) | Phys: 0.00 | Val: 5.7163 (25.33%) | Best: 26.77%\n",
            "Epoch 233 | T: 10s | Train: 0.2873 (90.0%) | Phys: 0.00 | Val: 5.7844 (24.55%) | Best: 26.77%\n",
            "Epoch 234 | T: 10s | Train: 0.2842 (90.0%) | Phys: 0.00 | Val: 5.7719 (24.35%) | Best: 26.77%\n",
            "Epoch 235 | T: 9s | Train: 0.2821 (90.2%) | Phys: 0.00 | Val: 5.7718 (24.50%) | Best: 26.77%\n",
            "Epoch 236 | T: 9s | Train: 0.2762 (90.4%) | Phys: 0.00 | Val: 5.7963 (24.46%) | Best: 26.77%\n",
            "Epoch 237 | T: 10s | Train: 0.2778 (90.1%) | Phys: 0.00 | Val: 5.7587 (24.23%) | Best: 26.77%\n",
            "Epoch 238 | T: 10s | Train: 0.2720 (90.5%) | Phys: 0.00 | Val: 5.8246 (24.44%) | Best: 26.77%\n",
            "Epoch 239 | T: 9s | Train: 0.2710 (90.6%) | Phys: 0.00 | Val: 5.8056 (24.61%) | Best: 26.77%\n",
            "Epoch 240 | T: 10s | Train: 0.2736 (90.4%) | Phys: 0.00 | Val: 5.7531 (25.12%) | Best: 26.77%\n",
            "Epoch 241 | T: 9s | Train: 0.2644 (90.7%) | Phys: 0.00 | Val: 5.8198 (25.20%) | Best: 26.77%\n",
            "Epoch 242 | T: 9s | Train: 0.2595 (91.2%) | Phys: 0.00 | Val: 5.8264 (25.28%) | Best: 26.77%\n",
            "Epoch 243 | T: 10s | Train: 0.2619 (90.8%) | Phys: 0.00 | Val: 5.8950 (25.07%) | Best: 26.77%\n",
            "Epoch 244 | T: 10s | Train: 0.2597 (91.0%) | Phys: 0.00 | Val: 5.9214 (24.62%) | Best: 26.77%\n",
            "Epoch 245 | T: 9s | Train: 0.2589 (91.0%) | Phys: 0.00 | Val: 5.8336 (25.11%) | Best: 26.77%\n",
            "Epoch 246 | T: 9s | Train: 0.2532 (91.2%) | Phys: 0.00 | Val: 5.9196 (24.50%) | Best: 26.77%\n",
            "Epoch 247 | T: 10s | Train: 0.2560 (91.1%) | Phys: 0.00 | Val: 5.8723 (24.89%) | Best: 26.77%\n",
            "Epoch 248 | T: 9s | Train: 0.2493 (91.3%) | Phys: 0.00 | Val: 5.9134 (24.78%) | Best: 26.77%\n",
            "Epoch 249 | T: 9s | Train: 0.2439 (91.3%) | Phys: 0.00 | Val: 5.8757 (24.91%) | Best: 26.77%\n",
            "Epoch 250 | T: 10s | Train: 0.2454 (91.4%) | Phys: 0.00 | Val: 5.8720 (24.69%) | Best: 26.77%\n",
            "Epoch 251 | T: 10s | Train: 0.2408 (91.8%) | Phys: 0.00 | Val: 5.9448 (25.11%) | Best: 26.77%\n",
            "Epoch 252 | T: 10s | Train: 0.2413 (91.6%) | Phys: 0.00 | Val: 5.9358 (25.08%) | Best: 26.77%\n",
            "Epoch 253 | T: 10s | Train: 0.2382 (91.6%) | Phys: 0.00 | Val: 5.9351 (24.51%) | Best: 26.77%\n",
            "Epoch 254 | T: 9s | Train: 0.2379 (91.6%) | Phys: 0.00 | Val: 5.9941 (24.92%) | Best: 26.77%\n",
            "Epoch 255 | T: 9s | Train: 0.2347 (91.8%) | Phys: 0.00 | Val: 5.9403 (25.60%) | Best: 26.77%\n",
            "Epoch 256 | T: 10s | Train: 0.2299 (92.0%) | Phys: 0.00 | Val: 5.9762 (25.60%) | Best: 26.77%\n",
            "Epoch 257 | T: 10s | Train: 0.2303 (92.1%) | Phys: 0.00 | Val: 6.0217 (24.90%) | Best: 26.77%\n",
            "Epoch 258 | T: 9s | Train: 0.2298 (91.9%) | Phys: 0.00 | Val: 5.9900 (25.24%) | Best: 26.77%\n",
            "Epoch 259 | T: 9s | Train: 0.2259 (92.2%) | Phys: 0.00 | Val: 5.9752 (25.29%) | Best: 26.77%\n",
            "Epoch 260 | T: 10s | Train: 0.2254 (92.2%) | Phys: 0.00 | Val: 6.0441 (24.73%) | Best: 26.77%\n",
            "Epoch 261 | T: 10s | Train: 0.2232 (92.3%) | Phys: 0.00 | Val: 6.0653 (24.60%) | Best: 26.77%\n",
            "Epoch 262 | T: 9s | Train: 0.2213 (92.3%) | Phys: 0.00 | Val: 6.0733 (25.06%) | Best: 26.77%\n",
            "Epoch 263 | T: 10s | Train: 0.2177 (92.5%) | Phys: 0.00 | Val: 6.1234 (25.18%) | Best: 26.77%\n",
            "Epoch 264 | T: 9s | Train: 0.2169 (92.5%) | Phys: 0.00 | Val: 6.0854 (25.23%) | Best: 26.77%\n",
            "Epoch 265 | T: 9s | Train: 0.2190 (92.3%) | Phys: 0.00 | Val: 6.0636 (24.54%) | Best: 26.77%\n",
            "Epoch 266 | T: 10s | Train: 0.2179 (92.5%) | Phys: 0.00 | Val: 6.0824 (25.10%) | Best: 26.77%\n",
            "Epoch 267 | T: 9s | Train: 0.2104 (92.7%) | Phys: 0.00 | Val: 6.0766 (25.77%) | Best: 26.77%\n",
            "Epoch 268 | T: 9s | Train: 0.2131 (92.7%) | Phys: 0.00 | Val: 6.1379 (25.17%) | Best: 26.77%\n",
            "Epoch 269 | T: 10s | Train: 0.2085 (92.7%) | Phys: 0.00 | Val: 6.1345 (25.04%) | Best: 26.77%\n",
            "Epoch 270 | T: 10s | Train: 0.2052 (92.9%) | Phys: 0.00 | Val: 6.1324 (25.12%) | Best: 26.77%\n",
            "Epoch 271 | T: 10s | Train: 0.2076 (92.8%) | Phys: 0.00 | Val: 6.1377 (25.34%) | Best: 26.77%\n",
            "Epoch 272 | T: 9s | Train: 0.2051 (92.8%) | Phys: 0.00 | Val: 6.1512 (25.42%) | Best: 26.77%\n",
            "Epoch 273 | T: 10s | Train: 0.2023 (92.8%) | Phys: 0.00 | Val: 6.1691 (24.70%) | Best: 26.77%\n",
            "Epoch 274 | T: 9s | Train: 0.2024 (92.9%) | Phys: 0.00 | Val: 6.1261 (25.07%) | Best: 26.77%\n",
            "Epoch 275 | T: 9s | Train: 0.1942 (93.1%) | Phys: 0.00 | Val: 6.1881 (24.87%) | Best: 26.77%\n",
            "Epoch 276 | T: 10s | Train: 0.1953 (93.1%) | Phys: 0.00 | Val: 6.1865 (24.85%) | Best: 26.77%\n",
            "Epoch 277 | T: 9s | Train: 0.1966 (93.1%) | Phys: 0.00 | Val: 6.2369 (25.73%) | Best: 26.77%\n",
            "Epoch 278 | T: 9s | Train: 0.1959 (93.1%) | Phys: 0.00 | Val: 6.1803 (25.89%) | Best: 26.77%\n",
            "Epoch 279 | T: 10s | Train: 0.1940 (93.2%) | Phys: 0.00 | Val: 6.1855 (25.56%) | Best: 26.77%\n",
            "Epoch 280 | T: 9s | Train: 0.1970 (93.2%) | Phys: 0.00 | Val: 6.2085 (25.14%) | Best: 26.77%\n",
            "Epoch 281 | T: 9s | Train: 0.1862 (93.5%) | Phys: 0.00 | Val: 6.2069 (25.49%) | Best: 26.77%\n",
            "Epoch 282 | T: 10s | Train: 0.1902 (93.4%) | Phys: 0.00 | Val: 6.1892 (25.54%) | Best: 26.77%\n",
            "Epoch 283 | T: 9s | Train: 0.1874 (93.4%) | Phys: 0.00 | Val: 6.3203 (25.12%) | Best: 26.77%\n",
            "Epoch 284 | T: 9s | Train: 0.1917 (93.4%) | Phys: 0.00 | Val: 6.2240 (25.08%) | Best: 26.77%\n",
            "Epoch 285 | T: 9s | Train: 0.1814 (93.7%) | Phys: 0.00 | Val: 6.2860 (25.37%) | Best: 26.77%\n",
            "Epoch 286 | T: 10s | Train: 0.1840 (93.5%) | Phys: 0.00 | Val: 6.2772 (25.06%) | Best: 26.77%\n",
            "Epoch 287 | T: 9s | Train: 0.1854 (93.6%) | Phys: 0.00 | Val: 6.2269 (25.22%) | Best: 26.77%\n",
            "Epoch 288 | T: 9s | Train: 0.1812 (93.8%) | Phys: 0.00 | Val: 6.2785 (24.94%) | Best: 26.77%\n",
            "Epoch 289 | T: 10s | Train: 0.1792 (93.7%) | Phys: 0.00 | Val: 6.3018 (25.37%) | Best: 26.77%\n",
            "Epoch 290 | T: 9s | Train: 0.1781 (93.8%) | Phys: 0.00 | Val: 6.3404 (25.15%) | Best: 26.77%\n",
            "Epoch 291 | T: 9s | Train: 0.1798 (93.7%) | Phys: 0.00 | Val: 6.3568 (25.23%) | Best: 26.77%\n",
            "Epoch 292 | T: 10s | Train: 0.1794 (93.8%) | Phys: 0.00 | Val: 6.3183 (25.47%) | Best: 26.77%\n",
            "Epoch 293 | T: 9s | Train: 0.1773 (93.9%) | Phys: 0.00 | Val: 6.3610 (25.06%) | Best: 26.77%\n",
            "Epoch 294 | T: 9s | Train: 0.1721 (93.9%) | Phys: 0.00 | Val: 6.4451 (24.83%) | Best: 26.77%\n",
            "Epoch 295 | T: 10s | Train: 0.1753 (93.8%) | Phys: 0.00 | Val: 6.4121 (25.00%) | Best: 26.77%\n",
            "Epoch 296 | T: 9s | Train: 0.1683 (94.1%) | Phys: 0.00 | Val: 6.3611 (25.59%) | Best: 26.77%\n",
            "Epoch 297 | T: 9s | Train: 0.1733 (93.9%) | Phys: 0.00 | Val: 6.3603 (25.32%) | Best: 26.77%\n",
            "Epoch 298 | T: 9s | Train: 0.1685 (94.1%) | Phys: 0.00 | Val: 6.4158 (25.27%) | Best: 26.77%\n",
            "Epoch 299 | T: 10s | Train: 0.1724 (94.2%) | Phys: 0.00 | Val: 6.4127 (24.95%) | Best: 26.77%\n",
            "Epoch 300 | T: 9s | Train: 0.1708 (94.1%) | Phys: 0.00 | Val: 6.3359 (25.91%) | Best: 26.77%\n",
            "Epoch 301 | T: 10s | Train: 0.1666 (94.2%) | Phys: 0.00 | Val: 6.4283 (25.13%) | Best: 26.77%\n",
            "Epoch 302 | T: 10s | Train: 0.1672 (94.1%) | Phys: 0.00 | Val: 6.4195 (25.59%) | Best: 26.77%\n",
            "Epoch 303 | T: 9s | Train: 0.1671 (94.1%) | Phys: 0.00 | Val: 6.4932 (24.94%) | Best: 26.77%\n",
            "Epoch 304 | T: 9s | Train: 0.1609 (94.4%) | Phys: 0.00 | Val: 6.4630 (25.28%) | Best: 26.77%\n",
            "Epoch 305 | T: 10s | Train: 0.1647 (94.3%) | Phys: 0.00 | Val: 6.5035 (25.18%) | Best: 26.77%\n",
            "Epoch 306 | T: 9s | Train: 0.1601 (94.5%) | Phys: 0.00 | Val: 6.4690 (25.03%) | Best: 26.77%\n",
            "Epoch 307 | T: 10s | Train: 0.1649 (94.3%) | Phys: 0.00 | Val: 6.4910 (25.44%) | Best: 26.77%\n",
            "Epoch 308 | T: 10s | Train: 0.1602 (94.5%) | Phys: 0.00 | Val: 6.4927 (25.23%) | Best: 26.77%\n",
            "Epoch 309 | T: 9s | Train: 0.1604 (94.4%) | Phys: 0.00 | Val: 6.4823 (24.97%) | Best: 26.77%\n",
            "Epoch 310 | T: 9s | Train: 0.1567 (94.6%) | Phys: 0.00 | Val: 6.5626 (24.86%) | Best: 26.77%\n",
            "Epoch 311 | T: 9s | Train: 0.1575 (94.4%) | Phys: 0.00 | Val: 6.5182 (24.84%) | Best: 26.77%\n",
            "Epoch 312 | T: 10s | Train: 0.1536 (94.6%) | Phys: 0.00 | Val: 6.5434 (25.53%) | Best: 26.77%\n",
            "Epoch 313 | T: 9s | Train: 0.1563 (94.5%) | Phys: 0.00 | Val: 6.5510 (25.39%) | Best: 26.77%\n",
            "Epoch 314 | T: 10s | Train: 0.1540 (94.7%) | Phys: 0.00 | Val: 6.5787 (25.26%) | Best: 26.77%\n",
            "Epoch 315 | T: 10s | Train: 0.1550 (94.6%) | Phys: 0.00 | Val: 6.5852 (25.21%) | Best: 26.77%\n",
            "Epoch 316 | T: 9s | Train: 0.1523 (94.7%) | Phys: 0.00 | Val: 6.5535 (25.66%) | Best: 26.77%\n",
            "Epoch 317 | T: 10s | Train: 0.1536 (94.6%) | Phys: 0.00 | Val: 6.6203 (25.49%) | Best: 26.77%\n",
            "Epoch 318 | T: 10s | Train: 0.1541 (94.6%) | Phys: 0.00 | Val: 6.5803 (24.47%) | Best: 26.77%\n",
            "Epoch 319 | T: 10s | Train: 0.1529 (94.7%) | Phys: 0.00 | Val: 6.6150 (25.54%) | Best: 26.77%\n",
            "Epoch 320 | T: 10s | Train: 0.1474 (94.8%) | Phys: 0.00 | Val: 6.5837 (25.43%) | Best: 26.77%\n",
            "Epoch 321 | T: 10s | Train: 0.1503 (94.7%) | Phys: 0.00 | Val: 6.5876 (25.11%) | Best: 26.77%\n",
            "Epoch 322 | T: 9s | Train: 0.1505 (94.7%) | Phys: 0.00 | Val: 6.5865 (25.31%) | Best: 26.77%\n",
            "Epoch 323 | T: 9s | Train: 0.1432 (95.0%) | Phys: 0.00 | Val: 6.6365 (25.56%) | Best: 26.77%\n",
            "Epoch 324 | T: 9s | Train: 0.1458 (94.8%) | Phys: 0.00 | Val: 6.6083 (25.09%) | Best: 26.77%\n",
            "Epoch 325 | T: 10s | Train: 0.1421 (95.0%) | Phys: 0.00 | Val: 6.6926 (25.39%) | Best: 26.77%\n",
            "Epoch 326 | T: 10s | Train: 0.1480 (94.7%) | Phys: 0.00 | Val: 6.6561 (25.39%) | Best: 26.77%\n",
            "Epoch 327 | T: 10s | Train: 0.1461 (94.8%) | Phys: 0.00 | Val: 6.6540 (25.51%) | Best: 26.77%\n",
            "Epoch 328 | T: 10s | Train: 0.1427 (95.0%) | Phys: 0.00 | Val: 6.7016 (25.32%) | Best: 26.77%\n",
            "Epoch 329 | T: 9s | Train: 0.1432 (95.0%) | Phys: 0.00 | Val: 6.6095 (25.66%) | Best: 26.77%\n",
            "Epoch 330 | T: 9s | Train: 0.1424 (95.0%) | Phys: 0.00 | Val: 6.6510 (25.51%) | Best: 26.77%\n",
            "Epoch 331 | T: 9s | Train: 0.1450 (94.9%) | Phys: 0.00 | Val: 6.6907 (25.28%) | Best: 26.77%\n",
            "Epoch 332 | T: 10s | Train: 0.1382 (95.1%) | Phys: 0.00 | Val: 6.6834 (25.32%) | Best: 26.77%\n",
            "Epoch 333 | T: 9s | Train: 0.1370 (95.2%) | Phys: 0.00 | Val: 6.6723 (25.52%) | Best: 26.77%\n",
            "Epoch 334 | T: 10s | Train: 0.1386 (95.2%) | Phys: 0.00 | Val: 6.7555 (24.78%) | Best: 26.77%\n",
            "Epoch 335 | T: 9s | Train: 0.1446 (94.9%) | Phys: 0.00 | Val: 6.7252 (25.23%) | Best: 26.77%\n",
            "Epoch 336 | T: 9s | Train: 0.1387 (95.1%) | Phys: 0.00 | Val: 6.6695 (25.96%) | Best: 26.77%\n",
            "Epoch 337 | T: 9s | Train: 0.1364 (95.2%) | Phys: 0.00 | Val: 6.7427 (25.49%) | Best: 26.77%\n",
            "Epoch 338 | T: 10s | Train: 0.1392 (95.2%) | Phys: 0.00 | Val: 6.6896 (25.20%) | Best: 26.77%\n",
            "Epoch 339 | T: 9s | Train: 0.1339 (95.3%) | Phys: 0.00 | Val: 6.7447 (25.55%) | Best: 26.77%\n",
            "Epoch 340 | T: 10s | Train: 0.1349 (95.2%) | Phys: 0.00 | Val: 6.7463 (25.40%) | Best: 26.77%\n",
            "Epoch 341 | T: 10s | Train: 0.1365 (95.2%) | Phys: 0.00 | Val: 6.7343 (25.63%) | Best: 26.77%\n",
            "Epoch 342 | T: 9s | Train: 0.1330 (95.4%) | Phys: 0.00 | Val: 6.7523 (25.76%) | Best: 26.77%\n",
            "Epoch 343 | T: 9s | Train: 0.1312 (95.4%) | Phys: 0.00 | Val: 6.8406 (25.06%) | Best: 26.77%\n",
            "Epoch 344 | T: 10s | Train: 0.1332 (95.4%) | Phys: 0.00 | Val: 6.7287 (25.48%) | Best: 26.77%\n",
            "Epoch 345 | T: 10s | Train: 0.1319 (95.4%) | Phys: 0.00 | Val: 6.8413 (25.46%) | Best: 26.77%\n",
            "Epoch 346 | T: 10s | Train: 0.1318 (95.5%) | Phys: 0.00 | Val: 6.7152 (25.59%) | Best: 26.77%\n",
            "Epoch 347 | T: 10s | Train: 0.1317 (95.4%) | Phys: 0.00 | Val: 6.7765 (25.14%) | Best: 26.77%\n",
            "Epoch 348 | T: 9s | Train: 0.1270 (95.6%) | Phys: 0.00 | Val: 6.8384 (25.22%) | Best: 26.77%\n",
            "Epoch 349 | T: 9s | Train: 0.1282 (95.5%) | Phys: 0.00 | Val: 6.8482 (25.35%) | Best: 26.77%\n",
            "Epoch 350 | T: 9s | Train: 0.1308 (95.5%) | Phys: 0.00 | Val: 6.8284 (25.63%) | Best: 26.77%\n",
            "Epoch 351 | T: 10s | Train: 0.1287 (95.4%) | Phys: 0.00 | Val: 6.8006 (25.22%) | Best: 26.77%\n",
            "Epoch 352 | T: 10s | Train: 0.1275 (95.5%) | Phys: 0.00 | Val: 6.8115 (25.60%) | Best: 26.77%\n",
            "Epoch 353 | T: 10s | Train: 0.1263 (95.6%) | Phys: 0.00 | Val: 6.8207 (25.94%) | Best: 26.77%\n",
            "Epoch 354 | T: 10s | Train: 0.1275 (95.6%) | Phys: 0.00 | Val: 6.8476 (25.74%) | Best: 26.77%\n",
            "Epoch 355 | T: 9s | Train: 0.1277 (95.6%) | Phys: 0.00 | Val: 6.8182 (25.63%) | Best: 26.77%\n",
            "Epoch 356 | T: 9s | Train: 0.1235 (95.7%) | Phys: 0.00 | Val: 6.8616 (25.15%) | Best: 26.77%\n",
            "Epoch 357 | T: 10s | Train: 0.1233 (95.7%) | Phys: 0.00 | Val: 6.9153 (25.17%) | Best: 26.77%\n",
            "Epoch 358 | T: 10s | Train: 0.1239 (95.6%) | Phys: 0.00 | Val: 6.8610 (25.37%) | Best: 26.77%\n",
            "Epoch 359 | T: 9s | Train: 0.1248 (95.6%) | Phys: 0.00 | Val: 6.8602 (25.58%) | Best: 26.77%\n",
            "Epoch 360 | T: 10s | Train: 0.1219 (95.8%) | Phys: 0.00 | Val: 6.8519 (25.68%) | Best: 26.77%\n",
            "Epoch 361 | T: 9s | Train: 0.1262 (95.5%) | Phys: 0.00 | Val: 6.8631 (25.77%) | Best: 26.77%\n",
            "Epoch 362 | T: 9s | Train: 0.1211 (95.7%) | Phys: 0.00 | Val: 6.9299 (25.20%) | Best: 26.77%\n",
            "Epoch 363 | T: 9s | Train: 0.1255 (95.6%) | Phys: 0.00 | Val: 6.8611 (25.96%) | Best: 26.77%\n",
            "Epoch 364 | T: 10s | Train: 0.1213 (95.8%) | Phys: 0.00 | Val: 6.8938 (25.63%) | Best: 26.77%\n",
            "Epoch 365 | T: 9s | Train: 0.1181 (95.9%) | Phys: 0.00 | Val: 6.9575 (25.83%) | Best: 26.77%\n",
            "Epoch 366 | T: 9s | Train: 0.1212 (95.9%) | Phys: 0.00 | Val: 6.8795 (25.65%) | Best: 26.77%\n",
            "Epoch 367 | T: 10s | Train: 0.1197 (95.8%) | Phys: 0.00 | Val: 6.8668 (25.58%) | Best: 26.77%\n",
            "Epoch 368 | T: 9s | Train: 0.1214 (95.7%) | Phys: 0.00 | Val: 6.9118 (25.08%) | Best: 26.77%\n",
            "Epoch 369 | T: 9s | Train: 0.1162 (95.9%) | Phys: 0.00 | Val: 6.9560 (25.87%) | Best: 26.77%\n",
            "Epoch 370 | T: 10s | Train: 0.1196 (95.8%) | Phys: 0.00 | Val: 6.9557 (25.09%) | Best: 26.77%\n",
            "Epoch 371 | T: 9s | Train: 0.1136 (96.0%) | Phys: 0.00 | Val: 6.9318 (25.84%) | Best: 26.77%\n",
            "Epoch 372 | T: 9s | Train: 0.1161 (96.0%) | Phys: 0.00 | Val: 6.9816 (25.23%) | Best: 26.77%\n",
            "Epoch 373 | T: 9s | Train: 0.1164 (96.0%) | Phys: 0.00 | Val: 6.9483 (25.60%) | Best: 26.77%\n",
            "Epoch 374 | T: 9s | Train: 0.1131 (96.1%) | Phys: 0.00 | Val: 6.9672 (25.72%) | Best: 26.77%\n",
            "Epoch 375 | T: 9s | Train: 0.1142 (96.1%) | Phys: 0.00 | Val: 7.0040 (26.38%) | Best: 26.77%\n",
            "Epoch 376 | T: 9s | Train: 0.1123 (96.1%) | Phys: 0.00 | Val: 6.9791 (26.08%) | Best: 26.77%\n",
            "Epoch 377 | T: 10s | Train: 0.1124 (96.0%) | Phys: 0.00 | Val: 7.0069 (25.36%) | Best: 26.77%\n",
            "Epoch 378 | T: 10s | Train: 0.1160 (96.0%) | Phys: 0.00 | Val: 6.9694 (25.41%) | Best: 26.77%\n",
            "Epoch 379 | T: 9s | Train: 0.1151 (96.0%) | Phys: 0.00 | Val: 6.9807 (25.68%) | Best: 26.77%\n",
            "Epoch 380 | T: 10s | Train: 0.1123 (96.1%) | Phys: 0.00 | Val: 7.0047 (25.47%) | Best: 26.77%\n",
            "Epoch 381 | T: 9s | Train: 0.1113 (96.1%) | Phys: 0.00 | Val: 7.0560 (25.65%) | Best: 26.77%\n",
            "Epoch 382 | T: 9s | Train: 0.1098 (96.2%) | Phys: 0.00 | Val: 7.0698 (25.31%) | Best: 26.77%\n",
            "Epoch 383 | T: 10s | Train: 0.1115 (96.1%) | Phys: 0.00 | Val: 7.0710 (25.63%) | Best: 26.77%\n",
            "Epoch 384 | T: 9s | Train: 0.1112 (96.1%) | Phys: 0.00 | Val: 7.0011 (25.94%) | Best: 26.77%\n",
            "Epoch 385 | T: 9s | Train: 0.1093 (96.2%) | Phys: 0.00 | Val: 7.0750 (25.12%) | Best: 26.77%\n",
            "Epoch 386 | T: 9s | Train: 0.1096 (96.2%) | Phys: 0.00 | Val: 7.0998 (25.59%) | Best: 26.77%\n",
            "Epoch 387 | T: 9s | Train: 0.1055 (96.4%) | Phys: 0.00 | Val: 7.0801 (26.01%) | Best: 26.77%\n",
            "Epoch 388 | T: 9s | Train: 0.1089 (96.2%) | Phys: 0.00 | Val: 7.1519 (25.63%) | Best: 26.77%\n",
            "Epoch 389 | T: 9s | Train: 0.1109 (96.0%) | Phys: 0.00 | Val: 7.1190 (25.98%) | Best: 26.77%\n",
            "Epoch 390 | T: 10s | Train: 0.1097 (96.2%) | Phys: 0.00 | Val: 7.0550 (26.10%) | Best: 26.77%\n",
            "Epoch 391 | T: 10s | Train: 0.1067 (96.2%) | Phys: 0.00 | Val: 7.1013 (25.79%) | Best: 26.77%\n",
            "Epoch 392 | T: 10s | Train: 0.1040 (96.3%) | Phys: 0.00 | Val: 7.1266 (25.18%) | Best: 26.77%\n",
            "Epoch 393 | T: 10s | Train: 0.1100 (96.1%) | Phys: 0.00 | Val: 7.1060 (25.53%) | Best: 26.77%\n",
            "Epoch 394 | T: 9s | Train: 0.1030 (96.4%) | Phys: 0.00 | Val: 7.1200 (25.52%) | Best: 26.77%\n",
            "Epoch 395 | T: 9s | Train: 0.1078 (96.2%) | Phys: 0.00 | Val: 7.1150 (25.82%) | Best: 26.77%\n",
            "Epoch 396 | T: 10s | Train: 0.1052 (96.3%) | Phys: 0.00 | Val: 7.0914 (25.27%) | Best: 26.77%\n",
            "Epoch 397 | T: 9s | Train: 0.1062 (96.4%) | Phys: 0.00 | Val: 7.1520 (25.62%) | Best: 26.77%\n",
            "Epoch 398 | T: 9s | Train: 0.1046 (96.3%) | Phys: 0.00 | Val: 7.0490 (26.30%) | Best: 26.77%\n",
            "Epoch 399 | T: 9s | Train: 0.1066 (96.3%) | Phys: 0.00 | Val: 7.1359 (25.77%) | Best: 26.77%\n",
            "Epoch 400 | T: 9s | Train: 0.1026 (96.4%) | Phys: 0.00 | Val: 7.1041 (25.56%) | Best: 26.77%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "CIFAR-100 MLP Baseline",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}